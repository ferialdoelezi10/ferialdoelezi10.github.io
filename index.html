<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RecurrentModel Method</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
        }
        th, td {
            padding: 10px;
            border: 1px solid #ddd;
            text-align: left;
        }
        th {
            background-color: #f2f2f2;
        }
        .method {
            background-color: #f8f8f8;
        }
    </style>
</head>
<body>
    <h1>RecurrentModel Method</h1>
    <table>
        <tr>
            <th>Method</th>
            <th>Description</th>
        </tr>
        <tr>
            <td class="method">
                <pre><code>RecurrentModel(input_size, hidden_size, device='cpu')</code></pre>
            </td>
            <td>
                Initializes a RecurrentModel instance.
            </td>
        </tr>
    </table>

    <h2>Method Details</h2>
    <p>
        The <code>RecurrentModel</code> method initializes a recurrent neural network (RNN) model using the Gated Recurrent Unit (GRU) architecture. It takes the following arguments:
    </p>
    <ul>
        <li><strong>input_size</strong>: The size of the input data.</li>
        <li><strong>hidden_size</strong>: The size of the hidden state.</li>
        <li><strong>device</strong>: The device to run the model on. Default is 'cpu'.</li>
    </ul>
    <p>
        The <code>forward</code> method defines the forward pass of the model. It takes an input tensor <code>x</code> and returns the output tensor after passing through the GRU layer. The hidden state is initialized with zeros and updated during the forward pass.
    </p>

    <h2>Python Code</h2>
    <pre><code>
import torch
import torch.nn as nn
import torch.nn.functional as F

class RecurrentModel(nn.Module):
    """
        Initializes a RecurrentModel instance.

        Args:
        - input_size (int): The size of the input.
        - hidden_size (int): The size of the hidden state.
        - device (str): The device to run the model on. Default is 'cpu'.
    """
    def __init__(self, input_size, hidden_size, device='cpu'):
        super(RecurrentModel, self).__init__()
        self.device = device
        self.hidden_size = hidden_size
        self.gru = nn.GRU(input_size, hidden_size, batch_first=True)

    def forward(self, x):
        """
        Defines the forward pass of the model.

        Args:
        - x (torch.Tensor): Input tensor.

        Returns:
        - torch.Tensor: Output tensor after passing through the GRU layer.
        """
        # Initialize hidden state
        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(x.device)
        
        # Forward pass through GRU layer
        out, _ = self.gru(x, h0)
        
        return F.relu(out[:, -1, :])
    </code></pre>
</body>
</html>
